---
title: "Two group comparisons"
title-slide-attributes:
  data-background-color: "#197aa0"
  data-background-opacity: "0.9"
  data-background-image: "https://github.com/STAT540-UBC/stat540-ubc.github.io/raw/main/images/stat540-logo-s.png"
  data-background-size: 12%
  data-background-position: 95% 90%
author: "Keegan Korthauer"
date: "21 January 2025"
date-format: long
format: 
  revealjs:
    chalkboard: true
    slide-number: c/t
    width: 1600
    height: 900
    logo: "https://github.com/STAT540-UBC/stat540-ubc.github.io/raw/main/images/stat540-logo-s.png"
    echo: true
    theme: [default, ../custom.scss]
    show-notes: false
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
---

## Reminders

* Project groups posted to Canvas last week

* Intro Assignment due **Thursday Jan 23**

* [Initial Project Proposal](https://stat540-ubc.github.io/group_project_rubrics.html#initial-proposal-5-pts) due **Monday Jan 27** (Feedback in-class Jan 30)


## Today's learning objectives

* Understand **how** and **when** to carry out a t-test for comparing two population means

* Identify when alternative approaches (e.g. nonparametric) are more appropriate

* Avoid common pitfalls in interpretation of hypothesis tests and p-values

## Central dogma of statistics

![](img/statInference.png){fig-align="center"}

We want to understand a **population** (e.g. all individuals with a certain disease) but we can only study a **random sample** from it

[Image source: Josh Akey's Lecture notes](https://www.gs.washington.edu/academics/courses/akey/56008/lecture/lecture1.pdf)


## Hypothesis Testing in Genomics

::: columns
::: column
- Retina presents a model system for investigating **regulatory networks** underlying neuronal differentiation

- **Nrl** transcription factor is known to be important for Rod development
:::

::: column
![](img/paperRef.PNG){fig-align="center"}
![](img/cellTypes.png){fig-align="center"}
[Akimoto et al. (2006)](https://doi.org/10.1073/pnas.0508214103)
:::
:::

. . . 

**What happens if you delete *Nrl*?**

## Why a Hypothesis Test?

From the [Akimoto et al. (2006) paper](https://doi.org/10.1073/pnas.0508214103): 

>"we hypothesized that Nrl is the ideal transcription factor to gain insights into gene expression changes ..."

. . . 

::: callout-note
# Biological question

Is the expression level of gene *A* affected by knockout of the *Nrl* gene?
:::

. . . 

We can use **statistical inference** to answer this biological question!


## Statistical inference


::: columns
::: column
* Let's observe and study a **random sample** to make conclusions about a population: measure gene expression on a random sample of mice
* **Experimental design**:
  * 5 developmental stages (E16, P2, P6, P10, 4Weeks) 
  * 2 genotypes: Wild type (WT), Nrl Knockout (NrlKO) 
  * 3-4 replicates for each combination 
:::

::: column
![](img/NrlKOmouse.png){fig-align="center"}
:::
:::


## Reading in / exploring the data

* Data obtained from the [Gene Expression Omnibus (GEO)](https://www.ncbi.nlm.nih.gov/geo/) repository (accession [GSE4051](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE4051))

* Load directly into R session using [`GEOquery` package](https://www.bioconductor.org/packages/release/bioc/html/GEOquery.html) - see code below (which also refactors some of the metadata for convenience)

* Practice with this in Seminars 4 and 5 (Review lecture 3 for general principles)

```{r}
#| include: false
set.seed(3759) 
```

```{r}
#| output-location: column
#| code-line-numbers: "2,8"
# load libraries
library(GEOquery)
library(gridExtra)
library(tidyverse)
theme_set(theme_bw(base_size = 20))

# download and read in dataset
eset <- getGEO("GSE4051", getGPL = FALSE)[[1]]

# recode time points
pData(eset) <- pData(eset) %>%
  mutate(sample_id = geo_accession) %>%
  mutate(dev_stage =  case_when(
    grepl("E16", title) ~ "E16",
    grepl("P2", title) ~ "P2",
    grepl("P6", title) ~ "P6",
    grepl("P10", title) ~ "P10",
    grepl("4 weeks", title) ~ "4_weeks"
  )) %>%
  mutate(genotype = case_when(
    grepl("Nrl-ko", title) ~ "NrlKO",
    grepl("wt", title) ~ "WT"
  ))

pData(eset) <- pData(eset) %>%
  mutate(dev_stage = fct_relevel(dev_stage, "E16", "P2", "P6", "P10", "4_weeks")) %>%
  mutate(genotype = as.factor(genotype))
eset
```

## Two example genes: *Irs4* and *Nrl*

::: callout-note
# Biological questions

1. Is the expression level of gene *Irs4* truly different in NrlKO compared to WT?

2. Is the expression level of gene *Nrl* truly different in NrlKO compared to WT?
:::

. . . 

We can't answer these questions in general; we can *only* study these genes in collected data (**gene expression values from a random sample of mice**)

## Extract the two genes of interest

```{r}
#| output-location: column
# function to convert to tidy format
toLongerMeta <- function(expset) {
    stopifnot(class(expset) == "ExpressionSet")
    
    expressionMatrix <- exprs(expset) %>% 
    as.data.frame() %>%
    rownames_to_column("gene") %>%
    pivot_longer(cols = !gene, 
                 values_to = "Expression",
                 names_to = "sample_id") %>%
    left_join(pData(expset) %>% select(sample_id, dev_stage, genotype),
            by = "sample_id")
  return(expressionMatrix)
}

# convert to tidy format and extract two genes
twoGenes <- toLongerMeta(eset) %>% 
  filter(gene %in% c("1422248_at", "1450946_at")) %>%
  mutate(gene = ifelse(gene == "1422248_at", "Irs4", "Nrl")) 
twoGenes
```
What do you notice? 

## Visualizing *Irs4* and *Nrl* genes in our sample

::: {.panel-tabset}

## Code

```{r}
#| output: false
irsLim <- filter(twoGenes, gene == "Irs4") %>%
  ggplot(aes(y = Expression, x = genotype, colour = genotype)) + 
  geom_jitter(size = 2, alpha = 0.8, width = 0.2) +
  labs(title = "Irs4 gene") +
  theme(legend.position = "none")
             
nrlLim <- filter(twoGenes, gene == "Nrl") %>%
  ggplot(aes(y = Expression, x = genotype, colour = genotype)) + 
  geom_jitter(size = 2, alpha = 0.8, width = 0.2) +
  labs(title = "Nrl gene") +
  theme(legend.position = "none") 

grid.arrange(irsLim + ylim(5, 13), nrlLim + ylim(5, 13), ncol = 2)
```

## Output

```{r}
#| echo: false
grid.arrange(irsLim + ylim(5, 13), nrlLim + ylim(5, 13), ncol = 2)
```

:::


## Formulating our hypotheses

* **Experimental design:** (ignoring developmental time for now)
  - 2 conditions: WT *vs* NrlKO
  - observe the expression of many genes in a random sample of ~20 mice from each condition

* **Biological hypothesis:** for *some* genes, the expression levels are different between conditions

* **Statistical hypotheses:** (for each gene $g=1,...,G$)
  - H~0~ (null hypothesis): the expression level of gene $g$ is the ***same*** in both conditions
  - H~A~ (alternative hypothesis): the expression level of gene $g$ is ***different*** between conditions

::: {.fragment}  
  
::: {.callout} 

How might we test H~0~?

:::
:::

## Notation[^1]

Population parameters (unknown/unobservable):

$\mu_Y = E[Y]$ : the (population) expected expression of gene $g$ in WT mice

$\mu_Z = E[Z]$ : the (population) expected expression of gene $g$ in NrlKO mice


## Notation[^1] 

Random variables and statistics (we can estimate from data):

* $Y_i$ : expression of gene $g$ in the WT sample $i$

* $Z_i$: expression of gene $g$ in NrlKO sample $i$ 

* $Y_1, Y_2,..., Y_{n_Y}$ : a **random sample** of size $n_Y$ WT mice 

* $Z_1, Z_2,..., Z_{n_Z}$ : a **random sample** of size $n_Z$ NrlKO mice 

* $\bar{Y}=\frac{\sum_{i=1}^{n_Y}Y_i}{n_Y}$: sample mean of gene $g$ expression from WT mice

* $\bar{Z}=\frac{\sum_{i=1}^{n_Z}Z_i}{n_Z}$: sample mean of gene $g$ expression from NrlKO mice

[^1]: ignoring subscript for gene $g$ for now


## Is there enough evidence to reject H~0~?

### $H_0: \mu_Y = \mu_Z$

```{r}
#| echo:  FALSE
#| warning:  FALSE
grid.arrange(irsLim + ylim(5, 13), nrlLim + ylim(5, 13), ncol = 2)
```

**Statistical Inference**: random samples are used to learn about the population 


## What we observe: sample averages: $\bar{Y}$ vs $\bar{Z}$

::: columns
::: column
```{r}
#| warning: false
#| message: false
# calculate mean of each gene and genotype
meanExp <- twoGenes %>%
  group_by(gene, genotype) %>%
  summarize(meanExpr = mean(Expression)) %>%
  pivot_wider(names_from = genotype, values_from = meanExpr) %>% 
  mutate(diffExp = NrlKO - WT)
meanExp
```
:::

::: column
This code uses [tidy data wrangling functions](https://raw.githubusercontent.com/rstudio/cheatsheets/main/tidyr.pdf) to calculate:

* the mean expression of each gene per genotype group
* the difference in mean expression of each gene in Nrl KO vs WT groups
:::
:::


## Is the difference between $\bar{Y}$ and $\bar{Z}$ enough to reject H~0~?

``` {r}
#| echo:  FALSE
irsMean <-   irsLim +
             stat_summary(geom = 'point',
                          fun = 'mean',
                          color = 'black',
                          fill = 'black',
                          shape = 17,
                          size = 2) +
             stat_summary(aes(label=paste("mean = ",round(..y..,2))), 
                          fun = mean, 
                          geom="text",
                          color = 'black',
                          size=5, 
                          vjust = 3)

nrlMean <-   nrlLim +
             stat_summary(geom = 'point',
                          fun = 'mean',
                          color = 'black',
                          fill = 'black',
                          shape = 17,
                          size = 2) +
             stat_summary(aes(label=paste("mean = ",round(..y..,2))),
                          fun = mean, 
                          geom="text",
                          color = 'black',
                          size=5, 
                          vjust = 3)
                          
grid.arrange(irsMean + ylim(5, 13), nrlMean + ylim(5, 13), ncol = 2)
```

::: {.fragment}

- The sample means, $\bar{Y}$ vs $\bar{Z}$, by themselves are not enough to make conclusions about the population

- What is a "large" difference? "Large" relative to what?
:::

## Consider this artificial version of *Nrl* 

``` {r}
#| echo:  FALSE

set.seed(20220117)
artDat <- data.frame("Expression" = pmax(c(rnorm(30, mean = 5.25, sd = 3), rnorm(30, mean = 11.5, sd = 3)), 0), 
                     "genotype" = factor(c(rep("NrlKO", times = 30), rep("WT" , times = 30))))
levels(artDat$genotype) <- rev(levels(artDat$genotype))

artMean <- ggplot(artDat, aes(y = Expression, x = genotype, colour = genotype)) + 
             geom_jitter(alpha = 0.8, width = 0.2) +
             labs(title = "Artificial gene") +
             theme(legend.position = "none") +
             stat_summary(geom = 'point',
                          fun = 'mean',
                          color = 'black',
                          fill = 'black',
                          shape = 17,
                          size = 2) +
             stat_summary(aes(label=paste("mean = ",round(..y..,2))),
                          fun = mean, 
                          geom="text",
                          color = 'black',
                          size=5, 
                          vjust = 3)

# Combine plots together
grid.arrange(nrlMean + ylim(0, 16), 
             artMean + ylim(0, 16), nrow = 1)
```

. . . 

What can we use to interpret the size of the mean difference? $\frac{\bar{Y}-\bar{Z}}{??}$


## "Large" difference relative to what?

::: columns
::: column
"Large" relative to the **observed variation:**
:::

::: column
$$\frac{\bar{Y}-\bar{Z}}{\sqrt{Var(\bar{Y}-\bar{Z})}}$$
::: 
:::

``` {r}
#| echo:  false

# Combine plots together
grid.arrange(nrlMean + ylim(0, 16), 
             artMean + ylim(0, 16), nrow = 1)
```


## Quantifying observed variation

* Recall that if $Var(Y_i)=\sigma_Y^2$, then $Var(\bar{Y})=\frac{\sigma_Y^2}{n_Y}$

* Assume that the random variables within each group are *independent and identically distributed* (iid), and that the groups are independent. More specifically, that
  1. $Y_1, Y_2,..., Y_{n_Y}$ are iid, 
  2. $Z_1, Z_2,..., Z_{n_Z}$ are iid, and
  3. $Y, Z$ are independent. 
  
* Then, it follows that $Var(\bar{Z}-\bar{Y})=\frac{\sigma_Z^2}{n_Z}+\frac{\sigma_Y^2}{n_Y}$

. . . 

* If we also assume equal population variances:</big> $\sigma_Z^2=\sigma_Y^2=\sigma^2$, then
$$Var(\bar{Z}-\bar{Y})=\frac{\sigma_Z^2}{n_Z}+\frac{\sigma_Y^2}{n_Y}=\sigma^2\left[\frac{1}{n_Z}+\frac{1}{n_Y}\right]$$


## Reflect

::: callout-caution
# Stop!

But how can we calculate population variance $\sigma$ if it is **unknown**?
:::



## ...using the ______________ (combined, somehow)!

::: columns
::: column
``` {r}
#| warning:  false
#| message:  false
# calculate sample variance for each gene and genotype
twoGenes %>%
  group_by(gene, genotype) %>%
  summarize(groupVar = var(Expression))
```
For example, for Nrl in WT: 
$$\hat{\sigma}_Y^2 = S_Y^2=\frac{1}{n_Y-1}\sum_{i=1}^{n_Y}(Y_i-\bar{Y})^2=1.22$$
:::

:::column
```{r}
#| echo:  FALSE
#| fig-height: 8.5
#| fig-width: 4.5
grid.arrange(irsMean  + ylim(5, 13), nrlMean + ylim(5, 13), ncol = 1)
```
:::
:::



## Combining sample variances 

Plug these estimates into chosen formula for the variance of difference of sample means:

* Assuming **equal** variance of Y's and Z's

$$\hat{Var}(\bar{Z_n}-\bar{Y_n})=\hat{\sigma}_{\text{pooled}}^2\left[\frac{1}{n_Y}+\frac{1}{n_Z}\right]$$
$$\hat{\sigma}_{\text{pooled}}^2=S_Y^2\frac{n_Y-1}{n_Y+n_Z-2}+S_Z^2\frac{n_z-1}{n_Y+n_Z-2}$$


* Assuming **unequal** variance of Y's and Z's (Welch's t-test)

$$\hat{Var}(\bar{Z_n}-\bar{Y_n})=\hat{\sigma}_{\bar{Z}_n-\bar{Y}_n}^2=\frac{S_Y^2}{n_Y}+\frac{S_Z^2}{n_Z}$$

Recall: the 'hat' (^) is used to distinguish an 'estimate' from a 'parameter'



## Test Statistic

'Manual' calculation of $T=\frac{\bar{Z}_n-\bar{Y}_n}{\sqrt{\hat{Var}(\bar{Z_n}-\bar{Y_n})}}$ (for illustration):

::: {.panel-tabset}

## Pooled variances
```{r}
## compute sample variance of each gene/genotype
theVars <- twoGenes %>%
  group_by(gene, genotype) %>%
  summarize(groupVar = var(Expression))

## compute sample size in each group
nY <- with(twoGenes, sum(genotype == "WT" & gene == "Nrl"))
nZ <- with(twoGenes, sum(genotype == "NrlKO" & gene == "Nrl"))

## assuming unequal true variance
s2DiffWelch <- theVars %>% 
    mutate(s2Welch = groupVar / ifelse(genotype == "WT", nY, nZ)) %>%
    group_by(gene) %>%
    summarize(s2Welch = sum(s2Welch))
meanExp$s2DiffWelch <- s2DiffWelch$s2Welch

## assuming equal true variance
s2Pooled <- theVars %>% 
    mutate(s2Pool = groupVar * ifelse(genotype == "WT", 
                                       (nY - 1) / (nY + nZ - 2),
                                       (nZ - 1) / (nY + nZ - 2))) %>%
  group_by(gene) %>%
  summarize(s2Pool = sum(s2Pool))
meanExp$s2Diff <- s2Pooled$s2Pool * (1/nY + 1/nZ)
```

## t-statistics
```{r}
meanExp %>% 
    mutate(t = diffExp / sqrt(s2Diff)) %>%
    mutate(tWelch = diffExp / sqrt(s2DiffWelch))
```

:::

```{r}
#| include: false
# check that equal to t.test function
by(twoGenes, twoGenes$gene, function(theDat) {
  theDat$genotype <- factor(theDat$genotype, rev(levels(theDat$genotype)))
  t.test(Expression ~ genotype, theDat, var.equal = TRUE)
})

by(twoGenes, twoGenes$gene, function(theDat) {
  theDat$genotype <- factor(theDat$genotype, rev(levels(theDat$genotype)))
  t.test(Expression ~ genotype, theDat, var.equal = FALSE)
})
```

Can we now say whether the observed differences are 'big'?

. . . 

The difference is about half a standard deviation for *Irs4* and ~17 standard deviations for *Nrl*



## What to do with this statistic?

* The test statistic $T$ is a **random variable** because it's based on our **random sample**

* We need a measure of its **uncertainty** to determine how extreme our observed $T$ is:

  * If we were to repeat the experiment many times, what's the probability of observing a value of $T$ **as extreme** as the one we observed?

. . . 

* We need a probability distribution!

* However, this is unknown to us so we need to **make more assumptions**



## Null distribution assumptions

* If we know how our statistic behaves when the *null hypothesis is true*, then we can evaluate how extreme our observed data is

  * The **null distribution** is the probability distribution of $T$ under H~0~

. . . 

* Let's assume that $Y_i$ and $Z_i$ follow (unknown) probability distributions called $F$ and $G$:  
$$(Y_i \sim F, \text{ and } Z_i \sim G)$$

* Depending on the assumptions we make about $F$ and $G$, theory tells us specific **null distributions** for our test statistic


##

### Willing to assume that F and G are normal distributions?

::: columns
::: column 
**2-sample *t*-test** (equal variances):
$$T\sim t_{n_Y+n_Z-2}$$
:::

::: column
**Welch's 2-sample *t*-test** (unequal variances):
$$T\sim t_{<something\,ugly>}$$
:::
:::

::: {.fragment}

### Unwilling to assume that F and G are normal distributions? 

But you feel that n~Y~ and n~Z~ are large enough?

Then the t-distributions above (or even a normal distribution) are decent approximations

:::

::: {.fragment}

::: {.callout-tip}
# Review

Why could we assume the sampling distribution of $T$ is normally distributed when we have a large sample size?
:::

:::

## Student's *t*-distribution

Summary: $T=\frac{\bar{Z}_n-\bar{Y}_n}{\sqrt{\hat{Var}(\bar{Z_n}-\bar{Y_n})}}$ is a **random variable**, and under certain assumptions, we can prove that $T$ follows a *t*-distribution

![](img/tdist.png){fig-align="center"}

Recall that the *t*-distribution has one parameter: df = degrees of freedom



## Hypothesis testing: Step 1

### 1. Formulate your hypothesis as a statistical hypothesis

In our example:

$$H_0: \mu_Y = \mu_Z \, \text{ vs} \,\,\, H_A: \mu_Y \neq \mu_Z$$



## Hypothesis testing: Step 2

### 2a. Choose a test statistic

In our example: 2-sample *t*-test, with equal variance

### 2b. Compute the observed value for the test statistic

For our two example genes:

``` {r}
twoGenes %>% 
  group_by(gene) %>%
  summarize(t = t.test(Expression ~ genotype, var.equal=TRUE)$statistic)
```

::: callout-tip
This code uses a shortcut to computing the t-statistic using the `t.test` function
:::


## Hypothesis testing: Step 3

### 3. Compute the p-value

::: callout-note
# Definition

**p-value**: Probability of observing a test statistic at least as extreme as that observed, under the *null sampling distribution*
:::

For our two example genes:

``` {r}
twoGenes %>% 
  group_by(gene) %>%
  summarize(pvalue = t.test(Expression ~ genotype, var.equal=TRUE)$p.value)
```
::: callout-tip
The `t.test` function also computes the p-value for us
:::

## In other words, assuming that H~0~ is true: 

For *Irs4*, the probability of seeing a test statistic as extreme as that observed $(t = -0.53)$ is pretty high $(p = 0.6)$.

But for *Nrl*, the probability of seeing a test statistic as extreme as that observed $(t = -16.8)$ is extremely low $(p=6.76 \times 10^{-19})$


```{r}
#| echo:  false
#| warning:  false

# function modified from webr package to plot tail area of t-test
plot.test=function(x,...){
     lim <- 4
     if (abs(x$statistic) > 4){
       lim <- abs(x$statistic)
     }

     tests=c("Welch Two Sample t-test"," Two Sample t-test")
     if(!(x$method %in% tests)) {
          cat("Currently, ",x$method," is not supported")
          return(invisible(0))
     }
     (degf=x[[2]])
     statName=tolower(attr(x$statistic,"names"))
     statName
     alpha=1-attr(x$conf.int,"conf.level")
     
     alternative<-x$alternative
     (newalpha=alpha)
     if(alternative=="two.sided") newalpha=alpha/2

     qF=function(...){
          eval(parse(text=paste0("q",statName,"(...)")))
     }
     dF=function(...){

               eval(parse(text=paste0("d",statName,"(...)")))
     }
     x0 <- seq(-lim,lim,length=1000)
     if(x[[1]]>lim) {
       x0=c(x0,x[[1]])
     } else if(x[[1]] < -lim) {
       x0=c(x[[1]],x0)
     }
     x0
     y0=dF(x0,df=degf)
     y0
     
     x1=seq(min(lim+1, qF(p=1-x$p.value/2,df=degf)),lim,length=50)
     y1=dF(x1,df=degf)
     x2=seq(-lim,max(-lim - 1, qF(p=x$p.value/2, df=degf)),length=50)
     y2=dF(x2,df=degf)
     
     data=data.frame(x=x0,y=y0)
     data
     data1=data.frame(x=x1,y1=y1)
     data2=data.frame(x=x2,y1=y2)
     x
     label=paste0(sprintf("%9s",attr(x$statistic,"names"))," = ",
                   sprintf("%.03f",x$statistic))
     if(length(degf)==2) {
          label=c(label,paste0("num df=",degf[1],", denom df=",degf[2]))
     } else {
          label=c(label,paste0(sprintf("%9s","df")," = ",sprintf("%.0f",degf)))
     }

     if(x[[3]]>=0.00001) {
          label=c(label,paste0(sprintf("%9s","p")," = ",sprintf("%.5f",x[[3]])))
     } else {
          label=c(label,paste0(sprintf("%9s","p")," < 0.00001"))
     }
     label=stringr::str_pad(label,19,side="left")

     label=stringr::str_c(label,collapse="\n")
     label
     p2<-ggplot(data,aes_string(x="x",y="y"))+geom_line()
     if(alternative!="less")  p2<-p2+geom_area(data=data1,aes(x1,y1),fill="red",alpha=0.5)
     if(alternative!="greater")  p2<-p2+ geom_area(data=data2,aes(x2,y2),fill="red",alpha=0.5)
     p2
     if(abs(x$statistic)>lim) {
          hjust=1
     } else if(x$statistic>0) {
          hjust=-0.1
     } else hjust=0.1
     
     ypoint=dF(x$statistic,df=degf)
     ypoint
     xpoint=qF(p=1-newalpha,df=degf)
     xpoint2=qF(p=newalpha,df=degf)
    
     p2<-p2+geom_vline(xintercept=x[[1]], color="blue", linetype="dashed")
     p2<-p2+ annotate(geom="label",x=Inf,y=Inf,label=label,vjust=1.1,hjust=1.1)

     p2<-p2+labs(title=x$method,x=paste0(statName," statistic"),y="Probability Density")+theme(plot.title=element_text(hjust=0.5))

     p2
}


tres <- by(twoGenes, twoGenes$gene, function(theDat) {
  theDat$genotype <- factor(theDat$genotype, rev(levels(theDat$genotype)))
  t.test(Expression ~ genotype, theDat, var.equal = TRUE)
})


p1 <- plot.test(tres[[1]]) + ggtitle("Irs4") +
  theme(axis.title=element_text(size=20),
        plot.title = element_text(size = 30),
        legend.text=element_text(size=18))
p2 <- plot.test(tres[[2]]) + ggtitle("Nrl")+
  theme(axis.title=element_text(size=20),
        plot.title = element_text(size = 30),
        legend.text=element_text(size=18))

grid.arrange(p1, p2, nrow=1)

```



## Hypothesis Testing: Step 4

### 4. Make a decision about significance of results

* The decision should be based on a pre-specified significance level ($\alpha$)

* $\alpha$ is often set at 0.05. However, this value is arbitrary and may depend on the study.

::: columns
::: column
***Irs4***

Using $\alpha=0.05$, since the p-value for the Irs4 test is greater than 0.05, we conclude that there is **not enough evidence** in the data to claim that Irs4 has differential expression in WT compared to NrlKO models. 

We do not reject H~0~!
:::

::: column
***Nrl***

Using $\alpha=0.05$, since the p-value for the Nrl test is much less than 0.05, we conclude that there is **significant** evidence in the data to claim that *Nrl* has differential expression in WT compared to NrlKO models. 

We reject H~0~!
:::
:::



## `t.test` function in R

::: columns
::: column
Assuming equal variances
```{r, linewidth=50}
twoGenes %>% 
  filter(gene == "Nrl") %>%
  t.test(Expression ~ genotype, 
         var.equal=TRUE, data = .)
```
:::

::: column
Not assuming equal variances
```{r, linewidth=50}
twoGenes %>% 
  filter(gene == "Nrl") %>%
  t.test(Expression ~ genotype, 
         var.equal=FALSE, data = .)
```
:::
:::

::: callout-tip
Check out `?t.test` for more options, including how to specify one-sided tests
:::


## Interpreting p-values

Which of the following are true? (select all that apply)

 a. If the effect size is very small, but the sample size is large enough, it is possible to have a statistically significant p-value
 b. A study may show a relatively large magnitude of association (effect size), but a statistically insignificant p-value if the sample size is small
 c. A very small p-value indicates there is a very small chance the finding is a false positive

## Common p-value pitfalls

::: callout-caution
# Caution

Valid inference using p-values depends on accurate assumptions about null sampling distribution
:::

::: callout-caution
# Caution

A p-value is **NOT**:

- The probability that the null hypothesis is true

- The probability that the finding is a "fluke"

- A measure of the size or importance of observed effects
:::

{{< video https://www.youtube.com/embed/ax0tDcFkPic >}}


## Preview: "Genome-wide" testing of differential expression

- In genomics, we often perform thousands of statistical tests (e.g., a *t*-test per gene)

- The distribution of p-values across all tests provides good diagnostics/insights

- Is it mostly uniform (flat)? If not, is the departure from uniform expected based on biological knowledge?

- We will revisit these topics in greater detail in later lectures


## Different kinds of *t*-tests:


- One sample *or* **two samples**

- One-sided *or* **two sided**

- Paired *or* **unpaired**

- Equal variance *or* unequal variance



## Types of Errors in Hypothesis Testing

![](img/hypError.png){fig-align="center"}


$$ \alpha = P(\text{Type I Error}), \text{   } \beta = P(\text{Type II Error}), \text{   Power} = 1- \beta$$



## H~0~: "*Innocent until proven guilty*"


* The default state is $H_0 \rightarrow$ we only reject if we have enough evidence

* If $H_0$: Innocent and $H_A$: Guilty, then

    * Type I Error $(\alpha)$: Wrongfully convict innocent (*False Positive*)
    
    * Type II Error $(\beta)$: Fail to convict criminal (*False Negative*)

##

### Willing to assume that F and G are normal distributions?

::: columns
::: column 
**2-sample *t*-test** (equal variances):
$$T\sim t_{n_Y+n_Z-2}$$
:::

::: column
**Welch's 2-sample *t*-test** (unequal variances):
$$T\sim t_{<something\,ugly>}$$
:::
:::


### Unwilling to assume that F and G are normal distributions? 

But you feel that n~Y~ and n~Z~ are large enough?

Then the t-distributions above (or even a normal distribution) are decent approximations

::: callout-caution
# Stop!

What if we aren't comfortable assuming the underlying data generating process is normal **AND** we aren't sure our sample is large enough to invoke the CLT?
:::

## What are alternatives to the *t*-test?

* First, one could use the t test statistic but use a **permutation approach** to compute its p-value; we'll revisit this topic later

* *Non-parametric* tests are an alternative:

  - **Wilcoxon rank sum test** (Mann Whitney) uses ranks to test differences in population means

  - **Kolmogorov-Smirnov test** uses the empirical CDF to test differences in population cumulative distributions


## Wilcoxon rank sum test

- Rank all data, **ignoring the grouping** variable

- **Test statistic** = sum of the ranks for one group (optionally, subtract the minimum possible which is $\frac{n_Y(n_Y+1)}{2}$)

    - Alternative but equivalent formulation based on the number of $y_i, z_i$ pairs for which $y_i \geq z_i$

- The null distribution of such statistics can be worked out or approximated


## `wilcox.test` function in R

::: panel-tabset
# *Irs4*
```{r}
wilcox.test(Expression ~ genotype, 
            data = twoGenes %>% filter(gene == "Irs4"))
```

# *Nrl*
```{r}
wilcox.test(Expression ~ genotype, 
            data = twoGenes %>% filter(gene == "Nrl"))
```
:::


## Kolmogorov-Smirnov test (two sample)

- **Null hypothesis**: F = G, i.e. the distributions are the same

- Estimate each CDF with the empirical CDF (ECDF)

$$\hat{F}(x)=\frac{1}{n}\sum_{i=1}^n{I[x_i\leq{x}]}$$

- **Test statistic** is the maximum of the absolute difference between the ECDFs[^2]

$$max|\hat{F}(x)-\hat{G}(x)|$$

- Null distribution does not depend on F, G (!)

[^2]: I'm suppressing detail here



## Kolmogorov-Smirnov test (two sample)

```{r}
#| echo:  false
# create ECDF of data
sample1 <- twoGenes %>%
               filter(gene == "Nrl", genotype == "WT") %>%
               pull(Expression)
sample2 <- twoGenes %>% 
               filter(gene == "Nrl", genotype == "NrlKO") %>%
               pull(Expression)
cdf1 <- ecdf(sample1)
cdf2 <- ecdf(sample2)
# find min and max statistics to draw line between points of greatest distance

minMax <- seq(min(sample1, sample2), max(sample1, sample2), length.out=length(sample1)) 
x0 <- minMax[which( abs(cdf1(minMax) - cdf2(minMax)) == max(abs(cdf1(minMax) - cdf2(minMax))) )] 
y0 <- cdf1(x0) 
y1 <- cdf2(x0) 


# png(file = "c:/temp/ks.png", width = 1024, height = 768, type="cairo-png")
p1 <- twoGenes %>% 
  filter(gene == "Nrl") %>%
ggplot(aes(x = Expression, group = genotype, color = genotype))+
  stat_ecdf(size=1) +
    theme(legend.position ="top") +
    xlab("Expression") +
    ylab("ECDF") +
    #geom_line(size=1) +
    geom_segment(aes(x = x0[1], y = y0[1], xend = x0[1], yend = y1[1]),
        linetype = "dashed", color = "red") +
    geom_point(aes(x = x0[1] , y= y0[1]), color="red", size=8) +
    geom_point(aes(x = x0[1] , y= y1[1]), color="red", size=8) +
    theme(legend.title=element_blank()) + 
  ggtitle("Nrl")


# create ECDF of data
sample1 <- twoGenes %>%
               filter(gene == "Irs4", genotype == "WT") %>%
               pull(Expression)
sample2 <- twoGenes %>% 
               filter(gene == "Irs4", genotype == "NrlKO") %>%
               pull(Expression)
cdf1 <- ecdf(sample1)
cdf2 <- ecdf(sample2)
# find min and max statistics to draw line between points of greatest distance

minMax <- seq(min(sample1, sample2), max(sample1, sample2), length.out=length(sample1)) 
x02 <- minMax[which( abs(cdf1(minMax) - cdf2(minMax)) == max(abs(cdf1(minMax) - cdf2(minMax))) )] 
y02 <- cdf1(x02) 
y12 <- cdf2(x02) 


# png(file = "c:/temp/ks.png", width = 1024, height = 768, type="cairo-png")
p2 <- twoGenes %>% 
  filter(gene == "Irs4") %>%
ggplot(aes(x = Expression, group = genotype, color = genotype))+
  stat_ecdf(size=1) +
    theme(legend.position ="top") +
    xlab("Expression") +
    ylab("ECDF") +
    #geom_line(size=1) +
    geom_segment(aes(x = x02[1], y = y02[1], xend = x02[1], yend = y12[1]),
        linetype = "dashed", color = "red") +
    geom_point(aes(x = x02[1] , y= y02[1]), color="red", size=8) +
    geom_point(aes(x = x02[1] , y= y12[1]), color="red", size=8) +
    theme(legend.title=element_blank()) + 
  ggtitle("Irs4")

grid.arrange(p1, p2, nrow=1)
```



## `ks.test` function in R



::: panel-tabset
# *Irs4*
```{r}
Irs4gene <- twoGenes %>% 
  filter(gene == "Irs4")
ks.test(Irs4gene$Expression[Irs4gene$genotype == "WT"],
        Irs4gene$Expression[Irs4gene$genotype == "NrlKO"])
```

# *Nrl*
```{r}
Nrlgene <- twoGenes %>% 
  filter(gene == "Nrl")
ks.test(Nrlgene$Expression[Nrlgene$genotype == "WT"],
        Nrlgene$Expression[Nrlgene$genotype == "NrlKO"])
```
:::


## Discussion

1. What test(s) might be appropriate if your sample size is just barely large enough to invoke CLT, but you also have suspected outliers?

2. If more than one test is appropriate (e.g. *t*-test, Wilcoxon, and KS), which should we report?

3. What is generally more important for results interpretation: the effect size or the p-value?

4. What should you do if methods that are equally appropriate and defensible give very different answers?

