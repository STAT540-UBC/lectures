---
title: "More `limma` & multiple testing"
title-slide-attributes:
  data-background-color: "#197aa0"
  data-background-opacity: "0.9"
  data-background-image: "https://github.com/STAT540-UBC/stat540-ubc.github.io/raw/main/images/stat540-logo-s.png"
  data-background-size: 12%
  data-background-position: 95% 90%
author: "Keegan Korthauer"
date: "6 February 2025"
date-format: long
format: 
  revealjs:
    chalkboard: true
    slide-number: c/t
    width: 1600
    height: 900
    logo: "https://github.com/STAT540-UBC/stat540-ubc.github.io/raw/main/images/stat540-logo-s.png"
    echo: true
    theme: [default, ../custom.scss]
    show-notes: false
html-math-method:
  method: mathjax
  url: "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
---


```{r}
#| include: false
library(tidyverse)
library(gridExtra)
library(broom)
library(latex2exp)
library(limma)
library(GEOquery)
library(qvalue)
theme_set(theme_bw(base_size = 20))
```

## Learning objectives

1. Use `limma` to perform **genome-wide differential expression testing** on microarray data

2. Understand the key differences between `limma` and `lm`

3. Explain why **multiple testing** increases the number of errors we make by chance

4. Be able to adjust for multiple comparisons by controlling the **False Discovery Rate**

    * e.g. using Benjamini-Hochberg or Storey's q-value

## Recall: The hybrid estimator in `limma`

$$\tilde{s}^2_g = \frac{d_0s_0^2 + ds^2_g}{d_0 + d}$$

Recall that $(s_0, d_0)$ are the *prior* parameters for $\sigma^2_g$ (random variable):

$$\frac{1}{\sigma^2_g} \sim \frac{1}{d_0s_0^2} \chi^2_{d_0}$$

. . .

The prior parameters incorporate information from all genes which allows us to **shrink/nudge the gene-specific variances toward a common consensus**

* they are estimated from the data - the formulas for $(s_0, d_0)$ and their derivations are beyond the scope of the course, but `limma` takes care of the details for us

* note that $(s_0, d_0)$ **do not depend on** $g$

## Preview: `limma` workflow

![](img/limma_flow.png){fig-align="center" width="68%"}

## Functions that make your life easier

| Function               | Description                                                                                                                   |
|------------------------------|-----------------------------------------|
| `model.matrix`         | Takes in your data frame and makes a design matrix                                                                            |
| `limma::lmFit`         | Fits the linear model to each gene separately -- replace gene with "feature" depending on your data ('industrial scale' `lm`) |
| `limma::eBayes`        | Use output of linear regression to compute moderated *t* statistics                                                           |
| `limma::topTable`      | Query your results; sort your p-values; sort genes; Adjust for multiple comparisons                                           |
| `limma::decideTests`   | Identify which genes are significantly differentially expressed for each contrast                                             |
| `limma::makeContrasts` | Create the contrast matrix $C$ that you desire                                                                                |
| `limma::contrast.fit`  | Apply a contrast to your estimates                                                                                            |

## Getting help

![](img/limma_help.png){fig-align="center"}

-   [Bioconductor homepage for limma](https://bioconductor.org/packages/release/bioc/html/limma.html){preview-link="true"}
-   Bring up help pages for specific functions in RStudio, e.g. `?limma::topTable`

## `limma` step one: `lmFit`

::: columns
::: {.column width="70%"}

$$\mathbf{Y}_g = \mathbf{X} \boldsymbol\alpha_g + \boldsymbol\varepsilon_g,$$ 

* Within each gene observations are iid / constant variance

-   `lmFit()` carries out multiple linear regression on each gene

-   Usage: `lmFit(object, design)`

    -   `object` is a data.frame or matrix with features in rows and samples in columns (*G* genes by *N* samples), or other Bioconductor object such as [`ExpressionSet`](https://bioconductor.org/packages/devel/workflows/vignettes/maEndToEnd/inst/doc/MA-Workflow.html#42_Bioconductor_ExpressionSets)

    -   `design` is a design matrix (output of `model.matrix(y ~ x)`; *N* samples by $p+1$ parameters)
:::

::: {.column width="30%"}

![](img/exprset.png){fig-align="center"}

Bioconductor's ExpressionSet class; [image source](http://dx.doi.org/10.12688/f1000research.8967.1)
:::
:::

## Let's run `limma` for the interactive model with age (continuous) and genotype (factor)

$$\Large y_{ig} = \theta + \tau_{KO}x_{ig,KO} + \tau_{Age}x_{ig,Age} + \tau_{KO:Age}x_{ig,KO}x_{ig,Age}$$

* $i$ indexes mouse, $g$ indexes genes

-   $x_{ig,KO}$ is the indicator variable for the NrlKO group

-   $x_{ig,Age}$ is the continuous age variable

## Interactive model with age and genotype

Example gene (but we want to fit this model on all genes):

```{r}
#| fig-align: center
#| fig-width: 10
#| fig-height: 5.5
#| code-fold: true
#| message: false

# read in our dataset
eset <- getGEO("GSE4051", getGPL = FALSE)[[1]]

# recode time points
pData(eset) <- pData(eset) %>%
  mutate(sample_id = geo_accession) %>%
  mutate(dev_stage =  case_when(
    grepl("E16", title) ~ "E16",
    grepl("P2", title) ~ "P2",
    grepl("P6", title) ~ "P6",
    grepl("P10", title) ~ "P10",
    grepl("4 weeks", title) ~ "P28"
  )) %>%
  mutate(genotype = case_when(
    grepl("Nrl-ko", title) ~ "NrlKO",
    grepl("wt", title) ~ "WT"
  ))

# reorder factor levels, add continous age variable
pData(eset) <- pData(eset) %>%
  mutate(dev_stage = fct_relevel(dev_stage, "E16", "P2", "P6", "P10", "P28")) %>%
  mutate(genotype = as.factor(genotype)) %>%
  mutate(genotype = fct_relevel(genotype, "WT", "NrlKO")) %>%
  mutate(age = ifelse(dev_stage == "E16", -4,
                            ifelse(dev_stage == "P2", 2, 
                                   ifelse(dev_stage == "P6", 6, 
                                          ifelse(dev_stage == "P10", 10, 28)))))

# function to return tidy data that merges expression matrix and metadata
toLongerMeta <- function(expset) {
    stopifnot(class(expset) == "ExpressionSet")
    
    expressionMatrix <- lonExpressionressionMatrix <- exprs(expset) %>% 
    as.data.frame() %>%
    rownames_to_column("gene") %>%
    pivot_longer(cols = !gene, 
                 values_to = "expression",
                 names_to = "sample_id") %>%
    left_join(pData(expset) %>% select(sample_id, dev_stage, age, genotype),
            by = "sample_id")
  return(expressionMatrix)
}

# pull out gene of interest
Tmem_dat <- toLongerMeta(eset) %>% 
  filter(gene == "1441811_x_at") %>%
  mutate(gene = "Tmem176a") 

Tmem_plot <- ggplot(Tmem_dat, aes(x = age, y = expression, colour = genotype)) + 
  geom_point(alpha = 0.7) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Tmem176a") +
  ylim(5, 11) +
  xlab("age (days)") 
Tmem_plot
```

## Arranging `lmFit` input: Bioconductor way

```{r}
eset
```

## Arranging `lmFit` input: Separate expression/metadata

::: panel-tabset
# Data matrix

```{r}
myDat <- assayData(eset)$exprs
dim(myDat)
head(myDat)
```

# Sample metadata

```{r}
myMeta <- pData(eset)
head(myMeta)
```
:::

:::{.callout-warning}
What critical sanity check needs to be carried out if expression measurements are separate from the metadata?
:::


## Formulating `lmFit` input: Design Matrix

::: columns
::: column
Bioconductor way:

```{r, linewidth=50}
desMat <- model.matrix(~ genotype*age, 
                       data = pData(eset))
```

Equivalently, if using the separate way:

```{r}
#| eval: false
desMat <- model.matrix(~ genotype*age, 
                       data = myMeta)
```
:::

::: column
```{r}
desMat 
```
:::
:::

:::{.callout-important}
Using Bioconductor objects that store the measurements and metadata in one object reduces the risk of errors due to subsetting, reordering, etc.
:::

## Computation is fast

* Bioconductor way:

```{r}
system.time(gFit <- lmFit(eset, 
                          model.matrix(~ genotype*age, data = pData(eset))))
```

-   Equivalently, using the 'separate' way:

```{r}
#| eval: false
gFit <- lmFit(myDat, 
              model.matrix(~ genotype*age, data = myMeta))
```

-   Using `lmFit` to fit an interactive model on 45K probesets takes a fraction of a second

. . .

-   The time-intensive parts of an analysis: data wrangling, selecting a model, choosing how to parameterize it, and interpreting it

## Output of `lmFit`

::: columns
::: column
```{r}
summary(gFit)
```
:::

::: column
```{r}
nrow(eset)
nrow(eset)*4
ncol(eset)*4
```

::: fragment
-   OK... but where are the shrunken variance estimates?? How do I pull out p-values??

-   Actually, we haven't carried out the empirical Bayesian computation yet -- still need to run `eBayes()`!
:::
:::
:::

## Moderated *t*-tests using `eBayes`

::: columns
::: column
```{r}
summary(gFit)
```
:::

::: column
```{r}
summary(ebFit <- eBayes(gFit))
```
:::
:::

## Components of the empirical Bayes estimators


|      math       |                        description                         |      `limma::eBayes`       |       dimension       | in `lm`? |
|:-----:|:-------------------|:-----------|:-----|:-----:|
|     $s_g^2$  |               gene-specific residual variance                |   `sigma^2`   |         45K           | $\checkmark$  |
|       $d$       |             residual degrees of freedom $(n-p-1)$              | `df.residual` |        Scalar[^1]         | $\checkmark$  |
|     $s_0^2$     |          mean of inverse $\chi^2$ prior for $s_g^2$          |  `s2.prior`  | Scalar |               |
|      $d_0$      |               degrees of freedom for the prior               |  `df.prior`  | Scalar |               |
| $\tilde{s}_g^2$ | posterior mean of $s_g^2$ (moderated gene-specific residual variance)            |  `s2.post`   |         45K          |               |
| $\tilde{t}_g$   | moderated t statistics                                       |  `t`         | 45K$\times$p           |               |


[^1]: limma can handle more complicated models where this is not the same for each gene, so this is actually a vector of 45K copies of the number 35

## `topTable()` extracts output in a convenient format!

```{r}
#| eval: false
topTable(fit, coef = NULL, number = 10, genelist = fit$genes, adjust.method = "BH",
         sort.by = "B", resort.by = NULL, p.value = 1, lfc = 0, confint = FALSE)
```

* Refer to the help page (`?topTable`) for full details of each argument

* Summary of key `topTable` arguments:
    * `coef` is the argument where you specify the coefficient(s) you want to test for equality with zero (default is NULL; must be specified)
    * `number` lets you control size of hit list (default is 10)
    * `p.value` lets you specify a minimum adjusted p-value cutoff (default is 1)
    * `lfc` lets you specify a minimum observed effect size - log2 fold change (default is 0)
    * `sort.by` and `resort.by` give control over the ordering (default is by "B": log-odds that the gene is differentially expressed)
    * `adjust.method` specifies how/if to adjust p-values for multiple testing (default is BH)

## `topTable` in action: `genotypeNrlKO`

```{r}
topTable(ebFit, coef = "genotypeNrlKO")
```

- `topTable(ebFit, coef = 2)` is equivalent here, but _much less informative_!!

-  What is the null hypothesis here?

:::{.notes}
$H_0: \tau_{KO}=0$; this finds genes where the KO differs from WT *when age is zero*
:::

## Plot the top 6 probes for `genotypeNrlKO`

```{r}
#| code-fold: true
#| fig-width: 14
#| fig-height: 6.5
#| fig-align: center
#| message: false
# grab the gene names of the top 6 genes from topTable
keep <- topTable(ebFit, coef = "genotypeNrlKO", number = 6) %>%
  rownames()

# extract the data for all 6 genes in tidy format
topSixGenotype <- toLongerMeta(eset) %>% 
  filter(gene %in% keep) %>%
  mutate(gene = factor(gene, levels = keep))

ggplot(topSixGenotype, 
       aes(x = age, y = expression, color = genotype)) + 
  geom_point() +
  xlab("age (days)") +
  facet_wrap( ~ gene) + 
  stat_smooth(method="lm", se=FALSE, cex=0.5)
```

## `topTable` in action: `age`

```{r}
topTable(ebFit, coef = "age")
```

- `topTable(ebFit, coef = 3)` is equivalent here, but *much less informative*!!

- What is the null hypothesis here?

:::{.notes}
$H_0: \tau_{Age}=0$; this finds genes where age significantly affects gene expression *for WT*
:::

## Plot the top 6 probes for `age`

```{r}
#| code-fold: true
#| fig-width: 14
#| fig-height: 6.5
#| fig-align: center
#| message: false
# grab the gene names of the top 6 genes from topTable
keep <- topTable(ebFit, coef = "age", number = 6) %>%
  rownames()

# extract the data for all 6 genes in tidy format
topSixAge <- toLongerMeta(eset) %>% 
  filter(gene %in% keep) %>%
  mutate(gene = factor(gene, levels = keep))

ggplot(topSixAge, 
       aes( x = age, y = expression, color = genotype)) + 
             geom_point() +
             xlab("age (days)") +
             facet_wrap( ~ gene) + 
             stat_smooth(method="lm", se=FALSE, cex=0.5)
```


## `topTable` in action: `genotypeNrlKO:age`

```{r}
topTable(ebFit, coef = "genotypeNrlKO:age")
```

-   `topTable(ebFit, coef = 4)` is equivalent here, but _much less informative_!!

-   What is the null hypothesis here?

:::{.notes}
$H_0: \tau_{KO:Age}=0$; this finds genes where the effect of age is significantly different in each genotype
:::


## Plot the top 6 probes for `genotypeNrlKO:age`

```{r}
#| code-fold: true
#| fig-width: 14
#| fig-height: 6.5
#| fig-align: center
#| message: false
# grab the gene names of the top 6 genes from topTable
keep <- topTable(ebFit, coef = "genotypeNrlKO:age", number = 6) %>%
  rownames()

# extract the data for all 6 genes in tidy format
topSixItx <- toLongerMeta(eset) %>% 
  filter(gene %in% keep) %>%
  mutate(gene = factor(gene, levels = keep))

ggplot(topSixItx, 
       aes( x = age, y = expression, color = genotype)) + 
             geom_point() +
             xlab("age (days)") +
             facet_wrap( ~ gene) + 
             stat_smooth(method="lm", se=FALSE, cex=0.5)

```


## `topTable` in action: any effect of genotype


```{r}
topTable(ebFit, coef = c("genotypeNrlKO", "genotypeNrlKO:age")) 
```


- `topTable(ebFit, coef = c(2,4))` is equivalent here, but _much less informative_!!

- What is the null hypothesis here?

:::{.notes}
$H_0: \tau_{KO} = \tau_{KO:Age}=0$; this finds genes where any (additive and/or interaction) effect of genotype is significant
:::

## Plot the top 6 probes for any effect of genotype


```{r}
#| code-fold: true
#| fig-width: 14
#| fig-height: 6.5
#| fig-align: center
#| message: false
# grab the gene names of the top 6 genes from topTable
keep <- topTable(ebFit, coef = c("genotypeNrlKO", "genotypeNrlKO:age"), number = 6) %>%
  rownames()

# extract the data for all 6 genes in tidy format
topSixGenotypeMarginal <- toLongerMeta(eset) %>% 
  filter(gene %in% keep) %>%
  mutate(gene = factor(gene, levels = keep))

ggplot(topSixGenotypeMarginal, 
       aes( x = age, y = expression, color = genotype)) + 
             geom_point() +
             xlab("age (days)") +
             facet_wrap( ~ gene) + 
             stat_smooth(method="lm", se=FALSE, cex=0.5)
```


## Comparison of $s_g^2$ and $\tilde{s}_g^2$ (shrinkage!)

::: columns
:::{.column width="35%"}
Fill in the blank (increases or decreases):

1. For **large** variances, limma \_\_\_\_\_\_\_\_\_\_\_ the gene-specific variance estimates.

  
2. For **small** variances, limma \_\_\_\_\_\_\_\_\_\_\_ the gene-specific variance estimates.

::: 

:::{.column width="65%"}

:::{.panel-tabset}

# original scale

```{r}
#| code-fold: true
#| fig-width: 7
#| fig-height: 6
df <- data.frame(limma = ebFit$s2.post, 
                 lm = gFit$sigma^2)
shrinkplot <- ggplot(df, aes(y = limma, x = lm)) +
  geom_point(alpha=0.2) +
  geom_abline(intercept=0, slope=1, color="red") +
  ggtitle("Ests of gene-specific variance")
shrinkplot
```

# log-scale
```{r}
#| code-fold: true
#| fig-width: 7
#| fig-height: 6
shrinkplot +
  scale_x_log10() +
  scale_y_log10() 
```

This plot is on the log-scale to 'zoom in' on the low range
:::

:::
:::

## Comparison of interaction coefficient p-values

```{r}
#| echo: false
#| fig-align: center
#| fig-width: 8
allDat <- toLongerMeta(eset)

# this takes a while - let's save the results 
# so we don't have to run each time we knit
if (file.exists("data/lmpvals.rds")){
  lm_all <- readRDS("data/lmpvals.rds")
}else{
  lm_all <- allDat %>%
    group_by(gene) %>%
    do(tidy(lm(expression ~ genotype*age, .))) %>% 
    filter(term=="genotypeNrlKO:age") %>%
    pull(p.value)
  saveRDS(lm_all, "data/lmpvals.rds")
}

df <- data.frame(limma=topTable(ebFit, coef = "genotypeNrlKO:age", 
                                number=Inf, sort.by = "none")$P.Value,
                 lm=lm_all)

df %>% ggplot(aes(y=limma, x = lm)) +
  geom_point(alpha = 0.1) +
  geom_abline(intercept = 0, slope = 1, color="red") +
  ggtitle("p-value for genotypeNrlKO:age") 
```

- `r sum(df$limma > df$lm)` genes where limma p-value is *larger* than lm
- `r sum(df$limma < df$lm)` genes where limma p-value is *smaller* than lm

## Multiple testing

What do we do with our lists of thousands of p-values?

## Recall the two types of errors

![](img/errors.png){fig-align="center"}


## Error rates

![](img/hypError.png){fig-align="center"}

$$\alpha = P(\text{Type I Error}), \text{   } \beta = P(\text{Type II Error}), \text{   Power} = 1- \beta$$

## Type I Error rate for $m$ tests

::: columns
::: column

* $P(\text{incorrect decision} | H_0) = \alpha$

  - let $\alpha=0.05$

* $P(\text{correct decision} | H_0) = 1-\alpha = 0.95$

::: fragment

* $P(\text{correct decision on }m\text{ tests} | H_0) =$ $$(1-\alpha)^m = 0.95^m$$

* $P(\text{at least one error on }m\text{ tests} | H_0) =$ $$1 - (1-\alpha)^m =$$ $$1-0.95^m = \alpha_{FWER}$$

:::
:::

::: column
::: fragment
```{r}
#| code-fold: true
#| fig-width: 6
#| fig-height: 6
#| fig-align: center
df <- data.frame(m = seq(1,200)) %>%
  mutate(y = 1-0.95^m)
ggplot(df, aes(x = m, y = y)) +
  geom_line(size = 1.5, alpha = 0.7, colour = "dodgerblue") +
  xlab("m (number of tests)") +
  ylab(expression(paste(1-0.95^m, " (FWER)")))
```
:::
:::
:::

## Multiple comparisons in genomics

::: {.r-stack}

![](img/mc1.png){height=800}

::: {.fragment .fade-in-then-out}
![](img/mc2.png){height=800}
:::

::: {.fragment .fade-in-then-out}
![](img/mc3.png){height=800}
:::


::: {.fragment .fade-in-then-out}
![](img/mc4.png){height=800}
:::

::: {.fragment .fade-in}
![](img/mc5.png){height=800}
:::
:::

## Family-Wise Error Rate (FWER)

-   **FWER** is the probability of making at least one error when testing $m$ hypotheses

. . .

-   **Control the FWER**: limit the probability of making at least one incorrect decision

-   One example: the **Bonferroni** correction for $\alpha=0.05$:

    $$\text{If } P(\text{at least one error on }m \text{ tests}) \lt \alpha$$

    $$\Rightarrow P(\text{at least one error on }m \text{ tests}) \lt \sum_{i=1}^m P(\text{error on test }i)$$

    $$\sum_{i=1}^m P(\text{error on test }i) = m\alpha_{Bon}$$

    $$\alpha_{Bon} = \frac{\alpha}{m} = \frac{0.05}{m}$$


## Bonferroni correction: controlling the FWER

Can think of controlling the probability of at least one false positive in two ways:

1. **Adjust the p-values; keep same** $\alpha$:

$$p_{Bon,i}=mp_i$$
$$\text{ (to be more precise: } \, p_{Bon,i}=min(mp_i, 1))$$

$$\text{Then, threshold } p_{Bon,i} \text{ at } \alpha$$

2. **Adjust the** $\alpha$ threshold; keep same p-values:

$$\alpha_{Bon}=\frac{\alpha}{m}$$
$$\text{Then, threshold } p_i \text{ at } \alpha_{Bon}$$


## Can we do better?

-   Bonferroni correction is very **conservative** (i.e. controls the FWER even lower than $\alpha$ in many settings)

-   Several other options are better

-   For example, the Holm procedure: multiplier for p-value correction is not the same for all genes; more powerful

$$p_{Holm, 1} = mp_1$$

$$p_{Holm,2} = (m-1)p_2$$ $$p_{Holm,3} = (m-2)p_3$$ $$\vdots$$ $$\Rightarrow FWER \le \alpha$$ ---

## How practical is the FWER in high-throughput biology?

-   Why do we care so much about making _one single error_??

```{=html}
<center>
<iframe src="https://giphy.com/embed/8mndEBLsg9Whg2Sduv" width="300" height="300" frameBorder="0" class="giphy-embed" allowFullScreen></iframe><p><a href="https://giphy.com/gifs/idk-preity-zinta-confuse-8mndEBLsg9Whg2Sduv"></a></p>
</center>
```
. . .

-   One easy way to ensure no Type I errors: reject no hypotheses! 😃

    -   However, then our power is zero... 😭

. . .

::: {.callout-important}
Being overly strict about Type I error leads to greater Type II error (loss of power)
:::


## Radical idea

:::{.callout-tip}
# FWER is not that relevant in high-throughput studies
It's OK to make multiple errors, as long as you also have a comparatively large number of true positives!
:::

```{=html}
<center>
<iframe src="https://giphy.com/embed/LqajRC2pU0Je8" width="480" height="289" frameBorder="0" class="giphy-embed" allowFullScreen></iframe><p><a href="https://giphy.com/gifs/mar-08-LqajRC2pU0Je8"></a></p>
<center>
```

## Enter: the False Discovery Rate (FDR)

::: columns
:::{.column width="65%"}

![](img/bh.png)
:::

:::{.column width="35%"}

[Benjamini Y, Hochberg Y. "**Controlling the False Discovery Rate: a Practical and Powerful Approach to Multiple Testing.**" *Journal of the Royal Statistical Society: Series B (Methodological)*. 1995 Jan;57(1): 289-300.]( https://doi.org/10.1111/j.2517-6161.1995.tb02031.x)

Over 110,000 citations to date!! 
:::
:::

## False Discovery Rate

![](img/fdrtable.png){fig-align="center"}

FDR is designed to control the expected proportion of false positives (V) among all hypotheses where the null has been rejected (R)

. . . 

$$FDR = E \Big[ \frac{V}{R} \Big]$$


## FDR vs FPR vs FWER

-   **False Discovery Rate (FDR)** is the rate that significant features $(R)$ are truly null

$$FDR = E \Big[ \frac{V}{R} \Big]$$

-   **False Positive Rate (FPR)** is the rate that truly null features $(m_0)$ are called significant

$$FPR =  E\Big[\frac{V}{m_0}\Big]$$

-   **Family-Wise Error Rate (FWER)** is the probability that the number of truly null features rejected $(V)$ is at least 1

$$\text{FWER } = P(V\ge1) $$

## Benjamini-Hochberg FDR (BH procedure)

-   Proposed the idea of controlling FDR instead of FWER

-   Proposed a procedure for doing so

    -   note that we know $R$, but we don't know $V$

-   Procedure: control FDR at level $q$

    1.  order the raw p-values $p_1 \le p_2 \le ...\le p_m$

    2.  find test with highest rank $j$ such that $p_j < \frac{jq}{m}$

    3.  declare all smaller ranks up to $j$ significant


## Controlling FDR at level $q$ = 0.05

::: {.r-stack}
:::{.fragment .fade-in-then-out}
| Rank $(j)$ | P-value |
|:---:|:---:|
|     1      | 0.0008  |
|     2      | 0.009   |
|     3      | 0.127   |
|     4      | 0.205   |
|     5      | 0.396   |
|     6      | 0.450   |
|     7      | 0.641   |
|     8      | 0.781   |
|     9      | 0.900   |
|     10     | 0.993   |

$\text{}$
:::

:::{.fragment .fade-in-then-out}
| Rank $(j)$ | P-value | BH-threshold: jq/m |
|:---:|:-----:|:--------:|
|     1      | 0.0008  | 0.005    |
|     2      | 0.009   | 0.010    |
|     3      | 0.127   | 0.015    |
|     4      | 0.205   | 0.020    |
|     5      | 0.396   | 0.025    |
|     6      | 0.450   | 0.030    |
|     7      | 0.641   | 0.035    |
|     8      | 0.781   | 0.040    |
|     9      | 0.900   | 0.045    |
|     10     | 0.993   | 0.050    |

$\text{}$
:::


:::{.fragment .fade-in-then-out}
| Rank $(j)$ | P-value | BH-threshold: jq/m |  BH-adjusted p-value: $p_{(i)}^{BH}= \text{min}(\text{min}_{j\ge i}(mp_{(j)}/j), 1)$ |
|:---:|:-----:|:----------:|:------------:|
|     1      | 0.0008  | 0.005    | 0.0080 |
|     2      | 0.009   | 0.010    | 0.0450 |
|     3      | 0.127   | 0.015    | 0.4233 |
|     4      | 0.205   | 0.020    | 0.5125 |
|     5      | 0.396   | 0.025    | 0.7500 |
|     6      | 0.450   | 0.030    | 0.7500 |
|     7      | 0.641   | 0.035    | 0.9157 |
|     8      | 0.781   | 0.040    | 0.9763 |
|     9      | 0.900   | 0.045    | 0.9930 |
|     10     | 0.993   | 0.050    | 0.9930 |

$\text{}$
:::

::: {.notes}
This formula looks more complicated than it really is. It says:

1. First, order all p-values from small to large. Then multiply each 𝑝
-value by the total number of tests 𝑚
 and divide by its rank order.
Second, make sure that the resulting sequence is non-decreasing: if it ever starts decreasing, make the preceding 𝑝
-value equal to the subsequent (repeatedly, until the whole sequence becomes non-decreasing).
If any 𝑝
-value ends up larger than 1, make it equal to 1.
:::

:::{.fragment .fade-in-then-out}
| Rank $(j)$ | P-value | BH-threshold: jq/m | Reject $H_0$? |
|:----:|:---------:|:----------:|:-------------:|
|     1      | 0.0008  | 0.005    | $\checkmark$  |
|     2      | 0.009   | 0.010    | $\checkmark$  |
|     3      | 0.127   | 0.015    |               |
|     4      | 0.205   | 0.020    |               |
|     5      | 0.396   | 0.025    |               |
|     6      | 0.450   | 0.030    |               |
|     7      | 0.641   | 0.035    |               |
|     8      | 0.781   | 0.040    |               |
|     9      | 0.900   | 0.045    |               |
|     10     | 0.993   | 0.050    |  $\text{ }$   |

$\text{}$
:::

:::{.fragment .fade-in}
| Rank $(j)$ | P-val | BH-thr: jq/m | Reject $H_0$? | $FWER < 0.05$? |
|:------:|---|:------------:|:---------:|:------:|
|     1      | 0.0008  | 0.005    | $\checkmark$  | $\checkmark$ |
|     2      | 0.009   | 0.010    | $\checkmark$  |    |
|     3      | 0.127   | 0.015    |               |    |
|     4      | 0.205   | 0.020    |               |    |
|     5      | 0.396   | 0.025    |               |    |
|     6      | 0.450   | 0.030    |               |    |
|     7      | 0.641   | 0.035    |               |    |
|     8      | 0.781   | 0.040    |               |    |
|     9      | 0.900   | 0.045    |               |    |
|     10     | 0.993   | 0.050    |               |    |

Where $\alpha_{Bon}=0.05/10=0.005$
:::
:::

## BH FDR values given in `limma` by default

```{r}
topTable(ebFit, coef = "genotypeNrlKO")
```

. . . 

Or, obtain them yourself for any vector of p-values `p` with `p.adjust(p, method="BH")`:


```{r}
pvals <- topTable(ebFit, coef = "genotypeNrlKO", number = Inf)$P.Value
p.adjust(pvals, method = "BH") %>% head()
```

## Other ways to control FDR

-   BH is just one (the first) method to control FDR

-   Since the publication of the BH method, other methods have been proposed

-   One of the most popular is [Storey's q-value](https://doi.org/10.1073/pnas.1530509100)

![](img/qval.png){fig-align="center"}

-   `qvalue` package implementation: provides adjusted p-values

## Storey's q-value vs BH (Conceptual)

-   Just like BH, is focused on the proportion of discoveries that are false positives

-   *Conceptual* difference between BH and Storey's q-value is:

    -   BH **controls** the FDR

    -   q-values give an unbiased **estimate** of the FDR (will control the FDR *on average*)


## Storey's q-value vs BH (Mathematical)

-   Mathematically, the difference between the two is in how $m_0$ is estimated

    -   Or equivalently, how $\pi_0=\frac{m_0}{m}$ is estimated (since $m$ is known)

    -   $\pi_0$ represents the overall proportion of tests that are truly null

-   q-value:

$$\hat{q}(p_i) = \min_{i\le j} \Big( \frac{\hat{\pi}_0m}{j}p_{(j)}\Big)$$

-   q-value and BH-adjusted p-values are equivalent when $\pi_0=1$

$$\hat{p}_{BH}(p_i) = \min_{i\le j} \Big(\frac{m}{j}p_{(j)}\Big)$$

(BH conservatively assumes that $\pi_0=1$)


## BH vs q-value in toy example

| Rank $(j)$ | P-value | $\hat{p}_{BH}(p_i)$ | $\hat{q}(p_i)$^[$\hat{\pi}_0=1$ in this case] |
|:----------:|---------|:--------------:|:--------------:|
|     1      | 0.0008  | 0.045               |     0.045      |
|     2      | 0.009   | 0.045               |     0.045      |
|     3      | 0.127   | 0.423               |     0.423      |
|     4      | 0.205   | 0.513               |     0.513      |
|     5      | 0.396   | 0.750               |     0.750      |
|     6      | 0.450   | 0.750               |     0.750      |
|     7      | 0.641   | 0.916               |     0.916      |
|     8      | 0.781   | 0.976               |     0.976      |
|     9      | 0.900   | 0.993               |     0.993      |
|     10     | 0.993   | 0.993               |     0.993      |


## BH vs q-value in effect of `genotypeNrlKO:age`

:::{.panel-tabset}

# Original scale
```{r}
#| fig-align: center
#| fig-width: 8
#| fig-height: 6.5
#| code-fold: true
# requires qvalue package
pvals <- topTable(ebFit, coef = "genotypeNrlKO:age", number = Inf)$P.Value

df <- data.frame(fdr.bh = p.adjust(pvals, method = "BH"),
                 fdr.q = qvalue::qvalue(pvals)$qvalues)

ggplot(df, aes(y = fdr.q, x = fdr.bh)) +
  geom_point(alpha = 0.1) +
  geom_abline(intercept = 0, slope = 1, color="red") +
  ggtitle("BH vs q-value for genotypeNrlKO:age") +
  xlim(0,1) +
  ylim(0,1)
```


# log-scale
```{r}
#| fig-align: center
#| fig-width: 8
#| fig-height: 6.5
#| code-fold: true

df <- mutate(df, 
             l_fdr.bh = -log10(fdr.bh),
             l_fdr.q = -log10(fdr.q))

ggplot(df, aes(y = l_fdr.q, x = l_fdr.bh)) +
  geom_point(alpha = 0.1) +
  geom_abline(intercept = 0, slope = 1, color="red") +
  ggtitle("BH vs q-value for genotypeNrlKO:age") +
  xlab("-log10(BH adjusted p-value)") +
  ylab("-log10(q-value)")
```
:::

## FDR control is an active area of research

::: columns
::: column

![](img/practicalguide.png)

[Korthauer\*, Kimes\* et al. 2019](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1716-1)

:::
::: column

![](img/practicalguidefig.png)
:::
:::


## Compounding issues of multiple comparisons

-   What if you're not only testing 20K genes, but also multiple tests per gene (e.g. multiple contrasts, such as several two-group comparisons)?

-   Classical procedures for adjustment:

    -   Tukey multiple comparison procedure
    -   Scheffe multiple comparison procedure
    -   Bonferroni or Holm FWER correction

-   In our setting, we can also apply BH to all p-values globally

    -   `limma::decideTests(pvals, method="global")` for a matrix of p-values or `eBayes` output (e.g. rows = genes, columns = contrasts)

    -   p-values are combined, adjusted globally, then separated back out and sorted



## Assumptions about p-values

::: {.callout-note}
Implicit assumption for all multiple testing correction methods: p-value distribution is "well-behaved"
:::

. . . 

What does this mean?

Primarily, that the distribution of p-values *under the null* is **uniform** (i.e. flat)

```{r}
#| echo: false
#| fig-align: center
set.seed(23)
pval <- replicate(2000, t.test(rnorm(100))$p.value)
hist(pval, breaks=30) 
```


## p-value distributions

Spike of small p-values indicates non-null tests.

```{r}
#| code-fold: true
#| fig-align: center
# plot histogram of p-values for genotypeNrlKO
hist(pvals)
```

Great primer on how things can go wrong: <http://varianceexplained.org/statistics/interpreting-pvalue-histogram/>


## What if p-values are *poorly behaved*?

-   FDR estimates can be invalid (assumptions are violated)

    -   Some possible causes: test assumptions violated, model misspecification, uncontrolled variation/batch effects, selection bias/filtering

-   Possible solution: nonparametric test

    - Limitation: lack of flexibility to adjust for multiple covariates

. . .

-   Another possible solution: estimate sampling distribution or p-values "empirically" using resampling techniques

    -   **Permutation**: construct a simulated version of your dataset that satisfies the null hypothesis and compute statistic (e.g. shuffle group labels for a two-group comparison); repeat many times and use permutation statistics as your sampling distribution rather than a t, Normal, F, $\chi^2$, etc

    -   Limitation: computationally intensive for genomics; not optimal for small sample sizes
    
## Next up: regression with count measures (RNA-seq)!

* So far, all of our modeling assumed our outcome $Y_i$ (gene expression measurements for a particular gene) were **continuous** and with **constant variance** (iid).  

* From RNA-seq, we obtain **discrete**, skewed distributions (with **non-constant variance**) of counts that represent gene expression levels across genes. These violate modeling assumptions for standard linear regression / limma.

* Next time, we'll explore:

    - Data transformations and extensions to limma framework to apply deal with these violations
    
    - Generalized linear models (negative binomial regression) to directly model counts 