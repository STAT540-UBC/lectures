---
title: "GWAS: linear mixed effect model"
author: |
    | Yongjin Park
    | University of British Columbia
date: "`r format(Sys.time(), '%d %B, %Y')`"
classoption: "aspectratio=169"
output:
    beamer_presentation:
        colortheme: "orchid"
        keep_tex: true
        latex_engine: xelatex
        slide_level: 2
header-includes:
  - \usepackage{cancel}
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{wrapfig}
  - \usepackage{float}
  - \usepackage{colortbl}
  - \usepackage{pdflscape}
  - \usepackage{tabu}
  - \usepackage{threeparttable}
  - \usepackage{threeparttablex}
  - \usepackage[normalem]{ulem}
  - \usepackage{makecell}
  - \usepackage{xcolor}
  - \AtBeginSection[]{\begin{frame}\frametitle{Today's lecture}{\Large\tableofcontents[currentsection]}\end{frame}}
  - |
    \makeatletter
    \def\ps@titlepage{%
      \setbeamertemplate{footline}{}
    }
    \addtobeamertemplate{title page}{\thispagestyle{titlepage}}{}
    \makeatother
    \include{toc}
---

## How do we deal with such a population structure in GWAS?

\large

:::::: {.columns}
::: {.column width=.45}

1. Consider these population structures as a "backdoor" variable and adjust or include them in the regression model

$${}$$

\begin{itemize}
\item<2-> We need to first estimate the population structures... Are there any uncertainty? Can we propagate the measurement errors?
\item<3-> Which variants are okay to include in the latent topic model?
\end{itemize}

:::
::: {.column width=.45}

\onslide<4->{
2. Treat such population structure-related effects as a "random" effect
}

$${}$$

\begin{itemize}
\item<5-> We can include some proxy random variables for population structures in a linear GWAS model
\item<6-> We might still need to consider uncertainty of the random effects
\end{itemize}

:::
::::::

## (digression) Useful facts on multivariate Gaussian distribution - 1

\large

If we have $\mathbf{y}$

$$\mathbf{y} \sim \mathcal{N}\!\left(\boldsymbol{\mu}, \Sigma\right)$$

then

$$\mathbb{E}\!\left[U^{\top}\mathbf{y}\right] = U^{\top} \boldsymbol{\mu},\quad
\mathbb{V}\!\left[U^{\top}\mathbf{y}\right] = U^{\top} \Sigma U$$

and (affine transformation)

$$U^{\top}\mathbf{y} \sim \mathcal{N}\!\left(U^{\top} \boldsymbol{\mu}, U^{\top} \Sigma U\right)$$

## (digression) Useful facts on multivariate Gaussian distribution - 2

\large

If we have two Gaussian random vectors, 
$\mathbf{y}\sim\mathcal{N}\!\left(\boldsymbol{\mu} + \mathbf{u}, \Sigma_{y}\right)$ and $\mathbf{u}\sim\mathcal{N}\!\left(\mathbf{u}|\mathbf{0}, \Sigma_{u}\right)$

\Large

Bayesian integration:

$$\int \mathcal{N}\!\left(\mathbf{y}|\boldsymbol{\mu} + \mathbf{u}, \Sigma_{y}\right) \mathcal{N}\!\left(\mathbf{u}|\mathbf{0}, \Sigma_{u}\right) d\mathbf{u} = \mathcal{N}\!\left(\mathbf{y}|\boldsymbol{\mu}, \Sigma_{y} + \Sigma_{u}\right)$$

\normalsize

A key idea in the proof:

$$\left[ \Sigma_{y}^{-1} - \Sigma_{y}^{-1}\left(\Sigma_{y}^{-1} + \Sigma_{u}^{-1} \right)^{-1}\Sigma_{y}^{-1} \right]^{-1} = \Sigma_{y} + \Sigma_{u}$$

by Woodbury identity.


## A linear model with population-driven random effects

\large

:::::: {.columns}
::: {.column width=.48}

A linear regression model:

\Large

$$\mathbf{y} = \mathbf{x}_{j} \underset{\textsf{\color{magenta} a fixed genetic effect}}{\beta_{j}} + \boldsymbol{\epsilon}$$

\large

What are we missing? Can we assume homo-scedasticity, i.e., 
$$\boldsymbol{\epsilon} \overset{?}{\sim} \mathcal{N}\!\left(\mathbf{0}, \sigma^{2}I\right)$$

:::
::: {.column width=.48}

\onslide<2->{

\large

A linear model with a random effect:

\Large

$$\mathbf{y} = \mathbf{x}_{j} \underset{\textsf{\color{gray} fixed}}{\beta_{j}} + \underset{\textsf{\color{magenta} random effect}}{\mathbf{u}} + \boldsymbol{\epsilon}$$

\large

{\emph Note}: There is no specific parameterization for this $n\times{1}$ random vector $\mathbf{u}$. Now, we assume:

$$\boldsymbol{\epsilon} \sim \mathcal{N}\!\left(\mathbf{0}, \sigma^{2}I\right)$$

}

:::
::::::

## A linear model with population-driven random effects - 2

\large

We want to capture unwanted population, cohort-specific random effects by $n \times 1$ vector $\mathbf{u}$ and \textbf{\color{magenta} remove} since our \textbf{\color{blue} goal} is to estimate the fixed genetic effect of a particular variant $j$.

\Large

$$\mathbf{y} = \mathbf{x}_{j} \underset{\textsf{\color{blue} goal}}{\beta_{j}} + \underset{\textsf{\color{magenta} remove}}{\mathbf{u}} + \boldsymbol{\epsilon}$$

\large

\begin{enumerate}
\item<2-> Note that $\mathbf{u}$ shouldn't be tied to a particular variant (by definition)
\item<3-> Also, the covariation of $\mathbf{u}$ is primarily driven by relatedness among individuals, not the variants. 
\end{enumerate}

\onslide<3->{
\Large
$$\mathbf{u} \sim \mathcal{N}\!\left(\mathbf{0}, \tau^{2} K\right),\quad
K \approx \frac{1}{n} XX^{\top}$$
}

## A linear mixed effect model (LMM) to test associations while adjusting population structure

\large
We can define a hierarchical model:

\Large

\begin{eqnarray}
\mathbf{y}|X,\beta,\mathbf{u},\sigma &\sim& \mathcal{N}\!\left(X\boldsymbol{\beta} + \mathbf{u}, \sigma^{2} I\right) \\
\mathbf{u}|\tau,K &\sim& \mathcal{N}\!\left(\mathbf{0}, \tau^{2} K\right)
\end{eqnarray}

\large

If we integrate out $\mathbf{u}$,

\Large

$$\mathbf{y}|X,\beta \sim \mathcal{N}\!\left(\mathbf{y} \, \middle| \, X \boldsymbol{\beta}, \underbrace{\tau^{2} K}_{\textsf{\color{magenta} genetic-relatedness matrix}} + \underbrace{\sigma^{2} I}_{\textsf{\color{teal} irreducible}}\right)$$


## Why using LMM instead of regressing out confounding factors?

\large

\begin{itemize}[<+->]
\item It is hard to distinguish between causative vs. confounding effects
\item Cumbersome computation required for matrix factorization or other latent variable modelling on a large genotype matrix
\item We many not have a large matrix to learn about non-genetic confounders...
\item One LMM estimation can substitute multiple matrix factorization steps
\item We may have a good idea about relationships induced by random effects!
\end{itemize}


## FaST Linear Mixed Model (Lippert *et al.* 2011)

\only<1-2>{

We can resolve maximum likelihood estimate of the parameters, $\boldsymbol{\beta}, \tau, \sigma$, 

$$\max \, \log \mathcal{N}\!\left(\mathbf{y} \, \middle| \, X \boldsymbol{\beta}, \sigma_{2} \left(\delta K + I \right)\right)$$

where $\tau^{2} = \delta \sigma^{2}$.
}

\only<2>{
We need to deal with this unfriendly form of likelihood:
$$-\frac{1}{2} \left(
n\log(2\pi\sigma^{2}) +
\log \left|I + \delta K \right| + 
\frac{1}{\sigma^{2}}\left[\mathbf{y} - X\boldsymbol{\beta}\right]^{\top} (I + \delta K)^{-1} \left[\mathbf{y} - X\boldsymbol{\beta}\right]
\right)$$
}

\only<3->{
Instead, we can transform the underlying distribution using spectral decomposition of the genetic-relatedness matrix (GRM), 

\large

$K = U S U^{\top}$ where $U^{\top}U=I$, and $S$ is a diagonal matrix.
}
\begin{eqnarray*}
\only<3-4>{
\underset{\textsf{\color{teal} projected output}}{U^{\top}\mathbf{y}} &\sim& \mathcal{N}\!\left(\underset{\textsf{\color{magenta} projected genotype}}{U^{\top}X}\boldsymbol{\beta}, \sigma^{2} U^{\top}(I + \delta K)U\right) \\
}
\only<4>{
\textsf{\color{gray} (by the affine transformation)}
&\sim& \mathcal{N}\!\left(\underset{\textsf{\color{pink} projected genotype}}{U^{\top}X} \boldsymbol{\beta},\, \underset{\textsf{\color{blue} diagonal matrix}}{\sigma^{2} (I + \delta S)}\right)
}
\end{eqnarray*}

\vfill
\only<4>{
\normalsize
\begin{itemize}
\item We can find $\beta$ by weighted least square
\item We can find $\sigma^{2}$ and $\delta$ by fixing $\beta$
\end{itemize}
}

\tiny

Lippert, Listgarten, .. , Heckerman, \emph{Nature Methods} (2011)

## A key research question in LMM: What covariance matrix?

\large
If there were many types of random effects,

$\mathbf{y} = \underset{\textsf{\color{magenta} fixed}}{X \boldsymbol{\beta}} + \underset{\textsf{\color{teal} random effects}}{\mathbf{u} + \mathbf{w} + \ldots} + \underset{\textsf{\color{gray} unknown}}{\epsilon}$

\onslide<2->{
We would need to many covariance matrices:

$$\mathbf{y}|\cdot \sim \mathcal{N}\!\left(X\boldsymbol{\beta},\,\sigma^{2}(I + \underbrace{\delta_{u} K_{u}  + \delta_{w} K_{w} + \ldots}_{\textsf{\color{teal} random effects}})\right)$$
}

\onslide<3>{
If we only care about variance decomposition $\beta_{j} \sim \mathcal{N}\!\left(0,\tau\right)$:

$$\mathbf{y} \sim \mathcal{N}\!\left(\mathbf{0},\, \sigma^{2}\left(\underset{\textsf{\color{magenta} observed genetic}}{\frac{\sigma^{2}_{\textsf{genetic}}}{n} XX^{\top}} + I + \underbrace{\delta_{u} K_{u}  + \delta_{w} K_{w} + \ldots}_{\textsf{\color{teal} random effects}}\right)\right)$$
}

## Should we worry about "over-fitting" in LMM?

\large 

An equivalent question for PCA-based confounder adjustment: 

\vfill

> How many PCs to adjust in GWAS?

> Can we include a candidate SNP in the GRM $K$ matrix?

\vfill

\only<2>{
For each chromosome $c \in \{1,\ldots, 22, \textsf{X}, \textsf{Y}\}$, build a leave-one-chromosome-out (LOCO) kinship matrix, say $K_{-c}$:

$$\mathcal{N}\!\left(\mathbf{y} | \mathbf{x}_{j} \beta_{j}, \sigma^{2} (\delta K_{-c} + I)\right)$$

\vfill
\tiny
Yang, {\it et al.}, \emph{Nature Genetics} (2014)

Tucker, Price, Berger, \emph{Genetics} (2014)
}

